{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Binance API Adapter using CCXT",
        "description": "Create a new Binance API adapter using the ccxt library. The adapter must be a 'drop-in' replacement for other adapters, strictly adhering to the existing foxtrot framework. It must mirror the structure, interface, and data transformations of the existing Interactive Brokers adapter to ensure system-wide compatibility without requiring any changes to the core system.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "The implementation should follow these steps:\n\n1.  **Project Setup:**\n    -   Create a new directory: `foxtrot/adapter/binance/`.\n    -   Add the `ccxt` library to the project's dependencies (e.g., `requirements.txt` or `package.json`).\n\n2.  **Adapter Class Structure:**\n    -   Create a `BinanceAdapter` class within the new directory that inherits from the framework's `foxtrot.gateway.BaseAdapter`.\n    -   The adapter will be initialized by the `MainEngine`, which will provide the `EventEngine` instance for event communication.\n    -   The constructor should accept API key, secret, and a flag for sandbox/testnet mode. It will initialize the `ccxt.binance()` instance.\n    -   Implement all abstract methods from `BaseAdapter`, such as: `connect()`, `disconnect()`, `send_order()`, `cancel_order()`, `query_market_data()`, `subscribe_tick()`, etc.\n\n3.  **CCXT Integration & Method Implementation:**\n    -   Use the initialized `ccxt` instance to implement the interface methods.\n    -   `connect()`: Should perform an initial authenticated call, like `fetchBalance()`, to verify credentials and then start the main data polling/streaming loop.\n    -   `send_order()`: Map the framework's `OrderRequest` object to `ccxt.createOrder()` arguments. Handle different order types and parameters.\n    -   `query_account()`: Use `ccxt.fetchBalance()` to retrieve account holdings.\n    -   `query_market_data()`: Use `ccxt.fetchOHLCV()` for historical candlestick data.\n\n4.  **Data Transformation Layer:**\n    -   Implement private helper methods to transform data between the Binance API format (via `ccxt`) and the framework's standard data objects (e.g., `OrderData`, `AccountData`, `BarData`, `TickData`).\n    -   **Symbols:** Convert from Binance format (e.g., 'BTCUSDT') to the internal format (e.g., 'BTC.USDT').\n    -   **Timestamps:** Convert millisecond epoch timestamps from `ccxt` to the application's standard format (e.g., ISO 8601 strings).\n    -   **Order Status:** Map Binance statuses ('open', 'closed', 'canceled') to the internal `OrderStatus` enum used by the foxtrot `OrderData` object.\n    -   **Numeric Types:** Use a high-precision numeric type like `Decimal` for all price and quantity values to avoid floating-point inaccuracies.\n\n5.  **Real-time Event Handling (WebSockets):**\n    -   Utilize `ccxt`'s unified WebSocket streaming methods (`watchTicker`, `watchOrders`, `watchMyTrades`).\n    -   Upon receiving a WebSocket message from `ccxt`, transform the data payload into standard `Event` objects (e.g., `TickEvent`, `OrderEvent`) containing the appropriate data objects (`TickData`, `OrderData`).\n    -   Put the created `Event` objects onto the `EventEngine` queue for system-wide distribution using the `on_tick` and `on_order` callback patterns.\n\n6.  **Error Handling:**\n    -   Wrap all `ccxt` calls in try/except blocks.\n    -   Catch specific `ccxt` exceptions (e.g., `AuthenticationError`, `InsufficientFunds`, `InvalidOrder`) and translate them into application-level `ErrorEvent` objects, which are then put on the `EventEngine` queue.",
        "testStrategy": "1.  **Unit Testing (Mocked CCXT):**\n    -   Create unit tests in `tests/unit/adapter/binance/`.\n    -   Use a mocking library to mock the `ccxt.binance` class.\n    -   **Transformation Tests:** Provide mock `ccxt` API responses and assert that the adapter's transformation logic produces the correct, fully-typed foxtrot data objects (`AccountData`, `OrderData`, `BarData`).\n    -   **Method Call Tests:** Call adapter methods like `send_order()` with a foxtrot `OrderRequest` and assert that the underlying `ccxt` methods are called with the correctly translated parameters.\n    -   **Error Handling Tests:** Configure the mock to raise `ccxt` exceptions and verify that the adapter handles them by putting a correctly formatted `ErrorEvent` on a mocked `EventEngine`.\n\n2.  **Integration Testing (Binance Testnet):**\n    -   Create a separate integration test suite that runs against the live Binance Spot Testnet.\n    -   Configure the tests to use dedicated testnet API keys stored securely as environment variables.\n    -   **Connectivity:** Test the `connect()` method to ensure successful authentication.\n    -   **Order Lifecycle:** Write a test that places a small limit order, verifies its status is 'open' via an `OrderEvent`, cancels the order, and verifies the final status is 'canceled' via another `OrderEvent`.\n    -   **Data Fetching:** Call `query_account()` and `query_market_data()` and validate the structure and types of the returned data objects against the framework's models.\n    -   **WebSocket Events:** Subscribe to a ticker (e.g., BTC/USDT) and order updates. Assert that correctly formatted `TickEvent` and `OrderEvent` objects are received via the `EventEngine` within a reasonable timeframe.\n\n3.  **Compatibility Testing:**\n    -   Execute an abstract, high-level test suite against both the existing IB adapter and the new Binance adapter to ensure they produce identical outputs and events for equivalent actions. This test is critical to validate the 'drop-in replacement' requirement and confirm strict interface compatibility.",
        "subtasks": [
          {
            "id": 1,
            "title": "Initial Project Setup and Adapter Scaffolding",
            "description": "Set up the project structure for the new Binance adapter and create the main `BinanceAdapter` class. This class will serve as the skeleton, inheriting from the `BaseAdapter` class and implementing its abstract methods with placeholder logic.",
            "status": "done",
            "dependencies": [],
            "details": "Create the directory `foxtrot/adapter/binance/`. Add `ccxt` to the project's dependencies. Create the `BinanceAdapter` class inheriting from `BaseAdapter`. The constructor should accept API credentials and be prepared to receive the `EventEngine` from the `MainEngine`. Implement all required public methods with their bodies raising `NotImplementedError`.",
            "testStrategy": "Create a basic unit test file. Write a test to verify that the `BinanceAdapter` class can be instantiated correctly with mock credentials and a mock `EventEngine`, and that it possesses all the abstract methods required by `BaseAdapter`."
          },
          {
            "id": 2,
            "title": "Implement RESTful Account and Order Management",
            "description": "Implement the essential account and order management methods using CCXT's REST API. This includes fetching account balances, placing, and canceling orders, along with the necessary data transformations into foxtrot objects and error handling.",
            "status": "done",
            "dependencies": [],
            "details": "Implement `connect()`, `query_account()`, `send_order()`, and `cancel_order()` using the corresponding `ccxt` methods (`fetchBalance`, `createOrder`, `cancelOrder`). Implement the data transformation layer for these methods, converting `ccxt` responses into the framework's `AccountData` and `OrderData` objects. Ensure all numeric values for price and quantity use the `Decimal` type. Handle specific `ccxt` exceptions by creating and queueing `ErrorEvent` objects.",
            "testStrategy": "Using a mocked `ccxt` instance, write unit tests to verify: 1. Correct mapping of a foxtrot `OrderRequest` to `ccxt` call arguments. 2. Accurate transformation of `ccxt` API responses into fully-populated `AccountData` and `OrderData` objects. 3. Proper creation of `ErrorEvent` objects when `ccxt` exceptions are raised."
          },
          {
            "id": 3,
            "title": "Implement RESTful Market Data Retrieval",
            "description": "Implement the functionality to fetch historical market data, specifically OHLCV (candlestick) data, from Binance via CCXT. This involves handling data requests and transforming the results into the framework's standard `BarData` format.",
            "status": "done",
            "dependencies": [],
            "details": "Implement the `query_market_data()` method using `ccxt.fetchOHLCV()`. The implementation must handle parameters such as symbol, timeframe, and date ranges. Create and apply data transformation logic to convert the OHLCV array from `ccxt` into a list of the framework's `BarData` objects, ensuring timestamps are converted to ISO 8601 strings and all price/volume values are `Decimal` objects.",
            "testStrategy": "Unit test the `query_market_data` method by providing a mocked `ccxt.fetchOHLCV` response. Assert that the returned list contains `BarData` objects and that their timestamp format and numeric types strictly match the framework's specifications."
          },
          {
            "id": 4,
            "title": "Implement Real-time WebSocket Data Streams",
            "description": "Integrate CCXT's unified WebSocket client to subscribe to real-time market data (ticks) and user-specific data (order updates). Received data must be transformed into standard foxtrot events and put on the EventEngine.",
            "status": "done",
            "dependencies": [],
            "details": "Implement `subscribe_tick()` and the logic for order updates using `ccxt.watchTicker()` and `ccxt.watchOrders()` respectively. In the asynchronous loop handling WebSocket messages, transform the data payload into `TickData` and `OrderData` objects. Wrap these objects in `TickEvent` and `OrderEvent` respectively, and put them onto the `EventEngine` queue. Implement the `disconnect()` method to gracefully close WebSocket connections.",
            "testStrategy": "Create unit tests that mock the `ccxt.watch*` methods. Simulate the reception of various WebSocket message types and assert that the correct transformation logic is applied and that properly formatted `TickEvent` and `OrderEvent` objects are passed to a mocked `EventEngine`'s queue."
          },
          {
            "id": 5,
            "title": "Finalize Error Handling and Perform Integration Testing",
            "description": "Conduct a comprehensive review of the adapter's error handling and perform integration testing against the Binance testnet. The goal is to ensure all API interactions are robust and exceptions are handled gracefully and consistently across the adapter.",
            "status": "done",
            "dependencies": [],
            "details": "Review all `try/except` blocks to ensure all relevant `ccxt` exceptions are caught and translated into standardized `ErrorEvent` objects. Add robust logging for errors and key events. Write an integration test suite that connects to the Binance testnet to execute an end-to-end workflow: connect, query balance, send an order, receive a WebSocket `OrderEvent`, query market data, and cancel the order.",
            "testStrategy": "The primary activity is to execute the integration test suite against the Binance testnet. These tests will require live testnet credentials (provided via environment variables) and will validate the complete, end-to-end functionality and reliability of the adapter under real network conditions, confirming it works correctly within the foxtrot framework."
          }
        ]
      },
      {
        "id": 2,
        "title": "Fix all failed unit tests",
        "description": "Fix all failed unit tests, grouping them by the reasons for failure and the classes being tested.\n\nThe following workflow must be followed:\n1. Each failing test must be analyzed by examining the source code first\n2. Make the necessary changes to fix the test\n3. Run the tests to verify the fix works\n4. Do not move on to the next test until the current one passes successfully\n\nThis systematic approach ensures each test is properly fixed before proceeding to the next one.",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "details": "",
        "testStrategy": "",
        "subtasks": [
          {
            "id": 1,
            "title": "Fix AttributeError in Futu Adapter Tests",
            "description": "Fix `AttributeError` in Futu Adapter Tests due to incorrect mocking.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Fix NameError in Futu Order Manager Tests",
            "description": "Fix `NameError` in Futu Order Manager Tests due to missing pandas import.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Fix AssertionError in Futu Account Manager Tests",
            "description": "Fix `AssertionError` in Futu Account Manager Tests due to incorrect mock setups and assertions.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 4,
            "title": "Fix AssertionError in Futu Historical Data Tests",
            "description": "Fix `AssertionError` in Futu Historical Data Tests due to incorrect mock calls.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 5,
            "title": "Fix AssertionError in Futu Market Data Tests",
            "description": "Fix `AssertionError` in Futu Market Data Tests due to an unexpected method call.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 6,
            "title": "Fix Failures in TUI Integration Tests",
            "description": "Fix `TypeError` and `AttributeError` in TUI Integration Tests.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 7,
            "title": "Fix Failures in Binance E2E Tests",
            "description": "Fix `AssertionError` in Binance E2E Tests.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 8,
            "title": "Fix Failures in Event Engine Performance Tests",
            "description": "Fix performance issues in Event Engine Performance Tests.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          },
          {
            "id": 9,
            "title": "Fix Failure in Event Type Tests",
            "description": "Fix `AssertionError` in Event Type Tests due to a change in the number of event types.",
            "status": "done",
            "dependencies": [],
            "details": "",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 3,
        "title": "Implement Real-Time WebSocket Streaming for Exchange Adapters",
        "description": "Replace the inefficient HTTP polling mechanism with a true WebSocket implementation to receive real-time market data. This task requires two fundamentally different integration strategies based on research findings: 1) **Unified Library Approach:** Utilize `ccxt.pro` for the Binance adapter, offering low implementation effort and easy maintenance. 2) **Native API Approach:** Implement bespoke, high-effort integrations for Futu and Interactive Brokers using their native SDKs to achieve complete feature access and optimal performance.",
        "status": "pending",
        "dependencies": [
          1,
          2
        ],
        "priority": "high",
        "details": "1. **Dependency Integration:**\n   - Add the `ccxt.pro` library to the project's dependencies. This will be the primary tool for exchanges it supports, such as Binance.\n\n2. **Architectural Refactoring:**\n   - Modify the `foxtrot.gateway.BaseAdapter` or create a new `StreamingBaseAdapter` to support persistent, asynchronous WebSocket connections.\n   - The adapter interface must include methods for `connect()`, `disconnect()`, `subscribe(symbol)`, and `unsubscribe(symbol)`.\n   - The adapter must manage the WebSocket connection in a non-blocking manner (e.g., using asyncio in Python or a separate thread) to avoid halting the `MainEngine`.\n\n3. **Unified Library Path (Binance):**\n   - Update the existing `BinanceAdapter` to utilize `ccxt.pro` for streaming data.\n   - Implement a long-running task that calls methods like `watch_order_book` or `watch_trades`.\n   - On receipt of data, transform it into the standardized `foxtrot` framework event objects and push them to the `EventEngine`.\n\n4. **Native API Path (Futu/IB):**\n   - For adapters like Futu and Interactive Brokers (IB), implement streaming clients using their native APIs.\n   - This is a more complex task requiring bespoke management of each exchange's specific connection, subscription, and event-handling logic, while still adhering to the common `StreamingBaseAdapter` interface.\n\n5. **Robust Connection Management:**\n   - Implement a resilient auto-reconnect mechanism with exponential backoff for all streaming adapters. Note that heartbeat handling and specific reconnect logic will need to be tailored to each exchange's API.\n   - Add comprehensive logging for connection status (connecting, connected, disconnected), subscription changes, and errors.",
        "testStrategy": "1. **Unit Testing (Mocked Clients):**\n   - In `tests/unit/adapter/`, create separate test suites that mock the `ccxt.pro` client (for Binance) and the native WebSocket clients (for Futu, IB).\n   - Simulate a full lifecycle of WebSocket events: connection success, data messages, heartbeats, errors, and disconnections.\n   - Verify that the adapter correctly parses incoming data payloads and pushes standardized events to a mock `EventEngine`.\n   - Test the auto-reconnect logic by simulating a disconnection and asserting that the adapter attempts to reconnect according to the backoff strategy.\n\n2. **Integration Testing (Live Testnet):**\n   - Configure tests to connect to exchange testnet/paper-trading environments (e.g., Binance Spot Testnet, IB Paper Trading).\n   - Write tests that subscribe to a live data feed, receive at least 10 updates, and then unsubscribe.\n   - Verify that the received data is correctly structured and reflects real-time market activity.\n   - Test connection resilience by programmatically interrupting the network connection and confirming that the adapter successfully reconnects.\n\n3. **Performance & Latency Benchmarking:**\n   - Create a benchmark test to measure the end-to-end latency from message receipt at the socket to event processing in the `EventEngine`.\n   - Compare latency metrics against the legacy HTTP polling system to formally validate the performance improvement.\n   - Conduct a stress test by subscribing to 20+ different streams simultaneously to monitor CPU, memory, and network usage under load.",
        "subtasks": [
          {
            "id": 1,
            "title": "Architect and Implement the StreamingBaseAdapter Interface",
            "description": "Create the foundational asynchronous architecture for WebSocket streaming. This involves defining a new abstract base class with a clear interface for managing persistent connections and data subscriptions, and integrating the `ccxt.pro` dependency in preparation for the first implementation.",
            "dependencies": [],
            "details": "Create a new `foxtrot.gateway.StreamingBaseAdapter` class. It must define the abstract async methods: `connect()`, `disconnect()`, `subscribe(symbol)`, and `unsubscribe(symbol)`. The design must support non-blocking, asynchronous operations (e.g., using `asyncio`). Add the `ccxt.pro` library to the project's dependencies.\n<info added on 2025-08-03T15:16:04.311Z>\nBased on a change in approach, the creation of a new `StreamingBaseAdapter` is no longer required. This task will now focus on adapting the existing `foxtrot.gateway.BaseAdapter` framework to support real-time WebSocket streaming. The implementation will use the `ccxt.pro` library to replace the current HTTP polling mechanism with a persistent WebSocket connection, ensuring the change is compatible with the existing `BaseAdapter` interface.\n</info added on 2025-08-03T15:16:04.311Z>\n<info added on 2025-08-03T15:16:48.334Z>\nThe task has been updated to reflect a new approach. The new title is \"Integrate ccxt.pro and Enhance BaseAdapter for WebSocket Support\". The description is now focused on adding the `ccxt.pro` dependency and enhancing the existing `BaseAdapter` implementations to support WebSocket connections, while maintaining the current interface. This is an implementation enhancement, not the creation of a new interface.\n</info added on 2025-08-03T15:16:48.334Z>\n<info added on 2025-08-03T15:42:49.480Z>\nIntegrate the `ccxt.pro` library to enhance the existing `foxtrot.gateway.BaseAdapter` with real-time WebSocket streaming capabilities. This task involves adding `ccxt.pro` to the project's dependencies and modifying the adapter's internal logic to use a persistent WebSocket connection instead of the current HTTP polling mechanism. The implementation must maintain the existing `BaseAdapter` interface, ensuring the change is a seamless enhancement rather than the creation of a new streaming-specific interface.\n</info added on 2025-08-03T15:42:49.480Z>\n<info added on 2025-08-03T15:44:17.989Z>\nThe title has been updated to \"Integrate ccxt.pro and Enhance BaseAdapter for WebSocket Support\" and the description has been refined to \"Add ccxt.pro dependency and enhance the existing BaseAdapter framework to support WebSocket streaming capabilities while maintaining the current interface\". The implementation details have been consolidated to reflect this single, current approach, removing historical notes.\n</info added on 2025-08-03T15:44:17.989Z>\n<info added on 2025-08-03T16:30:38.421Z>\nBased on a comprehensive design analysis using the CCXT.pro manual, the implementation plan has been updated with the following details:\n\n### Key Decision: Maintain BaseAdapter Interface\nNo breaking changes will be introduced; the WebSocket implementation will be internal to the adapter. This approach preserves backward compatibility with the existing framework.\n\n### Implementation Steps:\n\n1.  **Add ccxt.pro Dependency**\n    *   Update `pyproject.toml` to include `ccxt.pro ^4.4.0`.\n    *   Retain the standard `ccxt` library to ensure compatibility and provide an HTTP fallback mechanism.\n\n2.  **Enhance BinanceApiClient**\n    *   Initialize both `ccxt` and `ccxt.pro` exchange instances within the client.\n    *   Introduce a configuration flag to allow runtime selection between WebSocket and HTTP modes.\n    *   Implement a factory method for creating the appropriate exchange instance based on the selected mode.\n\n3.  **Create WebSocket Manager**\n    *   A new module will be created at `foxtrot/adapter/binance/websocket_manager.py`.\n    *   This manager will handle the connection lifecycle, including states for `DISCONNECTED`, `CONNECTING`, and `CONNECTED`.\n    *   It will feature an auto-reconnect mechanism with exponential backoff to handle connection drops gracefully.\n    *   It will also manage and persist subscription states across reconnections.\n\n4.  **Build Async-Threading Bridge**\n    *   A new utility module will be created at `foxtrot/util/websocket_utils.py`.\n    *   This module will manage a dedicated `asyncio` event loop running in a separate thread.\n    *   It will use `asyncio.run_coroutine_threadsafe()` to safely emit events from the `asyncio` loop to the main application's threading context, ensuring compatibility with the `BaseAdapter`'s existing threading model.\n\n### Test Strategy Enhancement:\n*   Mock `ccxt.pro` WebSocket operations to isolate and test adapter logic.\n*   Verify the full connection lifecycle, including all state transitions (`CONNECTING`, `CONNECTED`, `DISCONNECTED`, reconnect).\n*   Validate the functionality of the async-to-threading bridge to ensure thread-safe communication.\n*   Test the configuration flag to confirm seamless switching between WebSocket and HTTP modes.\n</info added on 2025-08-03T16:30:38.421Z>",
            "status": "pending",
            "testStrategy": "Unit test the base adapter's abstract structure. Create a dummy implementation to verify that method calls can be awaited and that the class structure is sound, without implementing a real network connection."
          },
          {
            "id": 2,
            "title": "Implement Binance WebSocket Adapter using the Unified `ccxt.pro` Library",
            "description": "Implement the 'Unified Library Approach' by refactoring the `BinanceAdapter` to inherit from `StreamingBaseAdapter` and use `ccxt.pro` for real-time data. This serves as the first concrete implementation of the new streaming architecture.",
            "dependencies": [
              "3.1"
            ],
            "details": "The `BinanceAdapter` must implement all methods from `StreamingBaseAdapter`. A long-running `asyncio` task should be created within the adapter to call `ccxt.pro` methods like `watch_order_book`. Upon receiving data, it must be transformed into standardized `foxtrot` event objects and pushed to the `EventEngine`.\n<info added on 2025-08-03T15:17:14.513Z>\nThis implementation will now refactor the existing `BinanceAdapter` to integrate `ccxt.pro`'s WebSocket capabilities while maintaining full compatibility with the `BaseAdapter` interface. Instead of inheriting from the new `StreamingBaseAdapter`, the focus is on replacing the internal HTTP polling logic with a persistent, long-running `asyncio` task that uses `ccxt.pro`'s `watch_*` methods. This ensures the adapter receives real-time data and pushes it to the `EventEngine` without altering its external-facing methods, allowing it to function as a drop-in upgrade within the current system architecture.\n</info added on 2025-08-03T15:17:14.513Z>\n<info added on 2025-08-03T15:44:51.694Z>\nRefactor the existing `BinanceAdapter` to integrate `ccxt.pro`'s WebSocket capabilities, replacing the internal HTTP polling logic. The implementation must maintain full compatibility with the `BaseAdapter` interface, ensuring the adapter functions as a drop-in upgrade.\n\nA persistent, long-running `asyncio` task will be implemented within the adapter. This task will use `ccxt.pro`'s `watch_*` methods to receive real-time data. Upon receipt, the data will be transformed into standardized `foxtrot` event objects and pushed to the `EventEngine`.\n</info added on 2025-08-03T15:44:51.694Z>\n<info added on 2025-08-03T15:45:18.871Z>\nRefactor the BinanceAdapter to use ccxt.pro WebSocket connections while maintaining BaseAdapter interface compatibility for seamless integration.\n</info added on 2025-08-03T15:45:18.871Z>\n<info added on 2025-08-03T16:31:17.780Z>\n## Core WebSocket Implementation for BinanceAdapter\n\n### Key Implementation Strategy:\nReplace HTTP polling loop with true WebSocket streaming using ccxt.pro's watch methods.\n\n### Technical Implementation:\n\n1.  **Transform BinanceMarketData._run_websocket()**\n    *   FROM: HTTP polling with 1-second sleep\n    *   TO: Async WebSocket loop with real-time streaming\n\n2.  **Async WebSocket Loop Architecture**\n    ```python\n    # Start WebSocket in dedicated asyncio thread\n    self.async_bridge.start()\n    self.async_bridge.run_async_in_thread(self._async_websocket_loop())\n    \n    # Main async loop with ccxt.pro integration\n    async def _async_websocket_loop(self):\n        websocket_manager = WebSocketManager(self.api_client.exchange, self.async_bridge)\n        while self._active:\n            # Use ccxt.pro watchTicker for real-time updates\n            async for ticker in self.api_client.exchange.watchTicker(symbol):\n                tick_data = self._convert_ticker_to_tick(ticker, symbol)\n                self.async_bridge.emit_event_threadsafe(Event(EVENT_TICK, tick_data))\n    ```\n\n3.  **Data Flow Implementation**\n    *   WebSocket receives ticker data via ccxt.pro\n    *   Convert CCXT format to Foxtrot TickData objects\n    *   Thread-safe event emission to EventEngine\n    *   Maintain subscription tracking for recovery\n\n4.  **Error Handling Integration**\n    *   Network errors trigger auto-reconnect\n    *   Symbol-specific errors don't affect other streams\n    *   Critical errors fallback to HTTP polling mode\n\n### Performance Targets:\n*   Latency: <200ms (vs current 1000ms)\n*   Zero data loss during normal operation\n*   Seamless reconnection without manual intervention\n\nThis implementation maintains full BaseAdapter compatibility while delivering real-time performance.\n</info added on 2025-08-03T16:31:17.780Z>",
            "status": "pending",
            "testStrategy": "In `tests/unit/adapter/`, mock the `ccxt.pro` client to simulate data streams, connection events, and errors. Assert that the adapter correctly transforms data payloads and pushes the appropriate `foxtrot` events to a mocked `EventEngine`."
          },
          {
            "id": 4,
            "title": "Implement Generic Auto-Reconnect and Connection Logging",
            "description": "Build a resilient and observable connection management system applicable to all streaming adapters. This involves creating a generic auto-reconnect mechanism with exponential backoff and adding structured logging for all connection lifecycle events.",
            "dependencies": [
              "3.2",
              "3.3"
            ],
            "details": "Enhance the `StreamingBaseAdapter` or a helper utility with a generic retry loop for the `connect` method. This loop must implement an exponential backoff delay. Add comprehensive logging for all connection state changes (e.g., CONNECTING, CONNECTED, DISCONNECTED, RECONNECTING) and subscription actions across all implemented adapters.\n<info added on 2025-08-03T15:23:40.457Z>\n[\n  3.2\n]\n</info added on 2025-08-03T15:23:40.457Z>\n<info added on 2025-08-03T15:46:09.168Z>\nCreate a generic, reusable auto-reconnect mechanism with exponential backoff and a structured logging system. This component will be used by all streaming adapters to ensure connection resilience and observability.\n\n**Key Requirements:**\n\n1.  **Auto-Reconnect Utility:** Implement a generic wrapper or helper that manages the connection lifecycle, automatically attempting to reconnect upon disconnection.\n2.  **Exponential Backoff:** The reconnect logic must use an exponential backoff delay between retries to avoid overwhelming the remote server.\n3.  **Structured Logging:** Add comprehensive logging for all critical events:\n    *   **Connection States:** `CONNECTING`, `CONNECTED`, `DISCONNECTED`, `RECONNECTING` (including retry attempt and delay).\n    *   **Subscription Actions:** `SUBSCRIBING`, `SUBSCRIBED`, `UNSUBSCRIBING`, `UNSUBSCRIBED`.\n</info added on 2025-08-03T15:46:09.168Z>\n<info added on 2025-08-03T15:46:38.718Z>\nTest Strategy:\n\n1.  **Unit Testing the Generic Reconnect Utility (using Binance Adapter):**\n    *   Create a dedicated test suite for the generic auto-reconnect and logging utility.\n    *   Instantiate the `BinanceAdapter` (from subtask 3.2) and wrap it with the new reconnect utility to serve as the concrete test subject.\n    *   **Simulate Connection Failures:** Mock the underlying `ccxt.pro` client's connect method to consistently raise exceptions.\n    *   **Verify Exponential Backoff:** Assert that the reconnect utility attempts to reconnect after delays that increase exponentially. Capture timestamps or mock the `asyncio.sleep` function to verify the delay duration for each attempt.\n    *   **Verify Logging:** Mock the logging system to capture log records. Assert that structured logs for `DISCONNECTED`, `RECONNECTING` (with retry count and delay), and `CONNECTED` are emitted at the correct stages of the lifecycle.\n    *   **Verify Successful Reconnect:** After simulating several failures, allow the mocked connect method to succeed. Assert that the system's state transitions to `CONNECTED` and that the retry loop is terminated.\n</info added on 2025-08-03T15:46:38.718Z>\n<info added on 2025-08-03T16:31:59.861Z>\n**Design Update based on Comprehensive Analysis:**\n\n**Implementation Strategy:**\nThe generic connection management system will be enhanced based on a more detailed design, potentially within a dedicated `WebSocketManager` class.\n\n**Core Component Enhancements:**\n*   **Subscription Restoration:** After a successful reconnection, the system must automatically restore all previously active subscriptions.\n*   **Connection Health Monitoring:** Implement a heartbeat mechanism to proactively monitor connection health and detect silent disconnections.\n*   **Circuit Breaker Pattern:**\n    *   Introduce a circuit breaker to track consecutive connection failures.\n    *   After a configurable threshold of failures, the system should automatically fall back to an alternative data source (e.g., HTTP polling).\n    *   The system must periodically test for WebSocket recovery before attempting to switch back from the fallback mechanism.\n*   **Specific Exponential Backoff Algorithm:**\n    *   Use the following parameters: `base_delay = 1.0s`, `max_delay = 60.0s`, `max_attempts = 50`. The delay should be calculated as `min(base_delay * (2 ** attempt), max_delay)`.\n*   **Enhanced Logging:** Error logs must include detailed context and a classification of the error type.\n\n**Test Strategy Enhancements:**\n*   Add test cases to validate that all subscriptions are correctly restored after a successful reconnection.\n*   Create specific tests to verify the circuit breaker's functionality, including its activation on repeated failures and its recovery process.\n</info added on 2025-08-03T16:31:59.861Z>",
            "status": "pending",
            "testStrategy": "In unit tests for both Binance and Futu adapters, simulate connection failures (e.g., by raising an exception from a mocked `connect` call) and assert that the reconnect logic is triggered with the correct backoff delays. Validate that log outputs capture the state changes accurately."
          },
          {
            "id": 5,
            "title": "Comprehensive Testing and Performance Validation",
            "description": "Execute a 3-layer testing strategy to validate WebSocket implementation reliability, performance, and production readiness",
            "details": "## Testing Strategy Overview\n\n### Layer 1: Unit Testing (95%+ Coverage)\n- Mock ccxt.pro WebSocket operations\n- Test connection lifecycle and state transitions\n- Validate async-to-threading bridge functionality\n- Test error scenarios and recovery mechanisms\n- Verify data transformation accuracy\n\n### Layer 2: Integration Testing\n- Use Binance testnet for real WebSocket validation\n- Test end-to-end data flow: WebSocket → EventEngine → MainEngine\n- Multi-symbol concurrent subscriptions (10+ symbols)\n- Network failure simulation and recovery testing\n- 24-hour stability testing\n\n### Layer 3: Performance Benchmarking\n**Targets:**\n- Average latency: <200ms (vs current 1000ms)\n- P95 latency: <500ms\n- Memory increase: <50MB per connection\n- CPU increase: <20% under normal load\n- Connection uptime: >99.5% over 24 hours\n\n**Benchmark Implementation:**\n```python\n# Latency measurement\nasync def test_latency_benchmarking():\n    latencies = []\n    def measure_latency(event):\n        latency = time.time() * 1000 - event.data.timestamp\n        latencies.append(latency)\n    \n    # Run for 5 minutes\n    await asyncio.sleep(300)\n    \n    avg_latency = sum(latencies) / len(latencies)\n    assert avg_latency < 200\n```\n\n### Test Files to Create:\n- `tests/unit/adapter/binance/test_websocket_manager.py`\n- `tests/unit/adapter/binance/test_market_data_websocket.py`\n- `tests/unit/util/test_websocket_utils.py`\n- `tests/integration/test_websocket_e2e.py`\n- `tests/performance/test_websocket_benchmarks.py`",
            "status": "pending",
            "dependencies": [
              "3.1",
              "3.2",
              "3.4"
            ],
            "parentTaskId": 3
          },
          {
            "id": 6,
            "title": "Production Deployment with Feature Flags and Monitoring",
            "description": "Implement feature flags, monitoring, and gradual rollout strategy for safe production deployment",
            "details": "## Production Deployment Strategy\n\n### Feature Flag Implementation\nConfigure WebSocket enablement through settings:\n```json\n{\n    \"websocket.enabled\": true,\n    \"websocket.symbols\": [\"BTCUSDT\", \"ETHUSDT\"],\n    \"websocket.fallback_on_error\": true,\n    \"websocket.max_reconnect_attempts\": 50,\n    \"websocket.reconnect_base_delay\": 1.0\n}\n```\n\n### Gradual Rollout Phases\n1. **Phase 1** (Day 1): Single symbol (BTCUSDT) testing\n2. **Phase 2** (Days 2-4): Top 5 liquid symbols\n3. **Phase 3** (Week 2): All major symbols\n4. **Phase 4** (Week 3): Full production deployment\n\n### Monitoring & Alerting Setup\n**Key Metrics:**\n- Connection uptime (target: >99%)\n- Average latency (alert: >300ms)\n- Reconnection rate (alert: >5/hour)\n- Error rate (alert: >5%)\n- Memory usage (alert: >50MB increase)\n- CPU usage (alert: >20% increase)\n\n### Circuit Breaker Configuration\n```python\nclass WebSocketCircuitBreaker:\n    def __init__(self):\n        self.failure_threshold = 5\n        self.recovery_timeout = 60\n        self.state = CircuitState.CLOSED\n```\n\n### Rollback Triggers\n- Error rate >5% over 5 minutes\n- Average latency >2x baseline (2000ms)\n- Connection stability <95% over 1 hour\n- Memory usage increase >100MB\n- Manual override capability\n\n### Recovery Procedures\n1. Test single symbol recovery\n2. Gradual re-enablement (5-minute validation)\n3. Expand to top symbols (10-minute validation)\n4. Full re-enablement after validation\n\n### Documentation Requirements\n- Operations runbook for monitoring\n- Rollback procedures guide\n- Performance baseline documentation\n- Troubleshooting guide",
            "status": "pending",
            "dependencies": [
              "3.5"
            ],
            "parentTaskId": 3
          }
        ]
      },
      {
        "id": 4,
        "title": "Stabilize Thread Management and Implement Graceful Shutdown",
        "description": "Resolve memory leaks in event handlers and implement robust thread lifecycle management, including graceful shutdown with timeouts and a monitoring system to improve overall system stability and reliability.",
        "details": "This task addresses critical stability issues related to threading, memory management, and application shutdown, which are exacerbated by the persistent connections introduced in the WebSocket streaming task.\n\n1. **Memory Leak Remediation in Event Handlers:**\n   - Utilize memory profiling tools (e.g., `memory-profiler`, `objgraph`) to inspect the `EventEngine` and `StreamingBaseAdapter` lifecycles.\n   - Focus on identifying reference cycles where event handlers keep adapter instances alive after they are disconnected.\n   - Implement explicit deregistration of all event listeners within the adapter's `disconnect` method to ensure proper garbage collection.\n\n2. **Graceful Shutdown Mechanism:**\n   - Implement a central shutdown hook that catches system signals (SIGINT, SIGTERM) or a dedicated 'shutdown' event.\n   - This hook will signal all active threads to stop using a `threading.Event` or similar mechanism.\n   - The main application thread will wait for all worker threads to terminate using `thread.join(timeout)` with a configurable timeout (e.g., 15 seconds).\n   - If any thread fails to terminate within the timeout, log a critical error and force the application to exit to prevent hangs.\n\n3. **Robust Thread Cleanup Logic:**\n   - Refactor the `StreamingBaseAdapter.disconnect()` method to be idempotent and comprehensive.\n   - It must guarantee that the underlying WebSocket client connection is closed, the worker thread is stopped, and all associated resources are released.\n   - This ensures that calling `disconnect` multiple times does not cause errors and that the adapter is left in a clean state.\n\n4. **Thread Monitoring and Diagnostics:**\n   - Create a `ThreadMonitor` service that runs as a daemon thread.\n   - This monitor will maintain a registry of all critical application threads (e.g., WebSocket adapter threads).\n   - Periodically, it will check `thread.is_alive()` on all registered threads. It will log thread counts and statuses.\n   - If a thread has terminated unexpectedly, the monitor will post a `THREAD_CRASHED` event to the `EventEngine`, including the thread's identity. This event can be used to trigger automated connection recovery logic.",
        "testStrategy": "1. **Memory Leak Verification:**\n   - Create a long-running test that repeatedly instantiates, connects, and disconnects a `StreamingBaseAdapter` (e.g., 1,000 iterations).\n   - Use `tracemalloc` to snapshot memory usage before and after the test loop. Assert that memory growth is minimal and not proportional to the number of iterations, confirming that objects are being garbage collected correctly.\n\n2. **Graceful Shutdown Testing:**\n   - Write an integration test that starts multiple mock adapters in separate threads and then triggers the application shutdown sequence.\n   - Verify that the `stop()` method is called on each adapter and that all threads are joined successfully within the timeout.\n   - Create a negative test with a 'rogue' mock adapter that intentionally ignores the stop signal. Assert that the shutdown process times out as expected, logs a critical error, and the main process still exits.\n\n3. **Thread Cleanup Unit Tests:**\n   - Write unit tests for the `StreamingBaseAdapter.disconnect()` method.\n   - Use mocks to verify that the underlying WebSocket client's `close()` method is called, the thread's `join()` method is invoked, and `EventEngine.unregister()` is called for all relevant event handlers.\n\n4. **Thread Monitor and Recovery Simulation:**\n   - Write a test where a mock adapter's thread is designed to crash after a few seconds.\n   - Assert that the `ThreadMonitor` detects the failure on its next check and correctly posts a `THREAD_CRASHED` event to the `EventEngine`.\n   - Create a mock listener for this event to verify that the recovery mechanism can be triggered.",
        "status": "pending",
        "dependencies": [
          3
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit and Document Existing Thread Usage",
            "description": "Conduct a comprehensive audit of the codebase to identify all instances of thread creation. Document the purpose, lifecycle, ownership, and shutdown mechanism for each thread, with a focus on the `StreamingBaseAdapter` and core services.",
            "dependencies": [],
            "details": "Use static analysis tools and manual code review to trace `threading.Thread` instantiations. The output should be a markdown document in the project's `docs/` directory, detailing each thread's role, how it's started, how it's intended to stop, and any potential for unmanaged proliferation. This document will serve as the foundation for all subsequent threading work.",
            "status": "pending",
            "testStrategy": "Verification will be done via peer review of the generated documentation. The review will confirm that all known threaded components, especially those related to Task 3 (WebSocket Streaming), have been accurately identified and described."
          },
          {
            "id": 2,
            "title": "Remediate Memory Leaks from Event Handler Reference Cycles",
            "description": "Utilize memory profiling tools to diagnose and fix memory leaks caused by persistent reference cycles between the `EventEngine` and `StreamingBaseAdapter` instances. Ensure adapters are properly garbage collected after disconnection.",
            "dependencies": [
              "4.1"
            ],
            "details": "Focus on the pattern where an adapter method is registered as an event handler, creating a cycle: `Adapter -> handler -> EventEngine -> handlers_list -> handler -> Adapter`. Implement an explicit `deregister` call within the adapter's `disconnect` method for all subscribed events. Use `objgraph` to visualize reference chains and `tracemalloc` to confirm memory is reclaimed.",
            "status": "pending",
            "testStrategy": "Create a long-running integration test that instantiates, connects, and disconnects an adapter in a loop (e.g., 10,000 iterations). Use `gc.collect()` and `tracemalloc` snapshots to assert that the memory usage of `StreamingBaseAdapter` objects does not grow over time."
          },
          {
            "id": 3,
            "title": "Implement a Centralized, Thread-Safe Shutdown Signal",
            "description": "Establish a single, globally accessible `threading.Event` to signal a system-wide shutdown. Refactor all long-running threads, particularly in `StreamingBaseAdapter`, to periodically check this event and exit their main loops cleanly when it is set.",
            "dependencies": [
              "4.1"
            ],
            "details": "Create a singleton or a context-managed object that holds the shutdown `threading.Event`. All worker threads' main loops (e.g., `while not self.shutdown_event.is_set():`) must be modified to honor this event. This provides a non-blocking, thread-safe way to request termination.",
            "status": "pending",
            "testStrategy": "Unit test the components that are modified to listen for the event. Mock the event object, set it, and assert that the thread's main loop terminates as expected within a short time frame. Verify that the thread does not terminate if the event is not set."
          },
          {
            "id": 4,
            "title": "Implement Graceful Shutdown Logic with Timeout and Forced Exit",
            "description": "Develop the main application's shutdown sequence. This involves catching system signals (SIGINT, SIGTERM), triggering the central shutdown event, and then waiting for all registered threads to terminate using `thread.join()` with a configurable timeout.",
            "dependencies": [
              "4.3"
            ],
            "details": "Use Python's `signal` module to register handlers for SIGINT and SIGTERM. The handler will set the shutdown event from subtask 4.3. The main thread will maintain a list of all critical worker threads. After setting the event, it will loop through this list, calling `join(timeout)`. If a join times out, log a critical error message specifying the hanging thread and call `os._exit(1)` to ensure the process terminates.",
            "status": "pending",
            "testStrategy": "Create an integration test with a mock 'hanging' thread that ignores the shutdown event. Run the application's shutdown procedure and assert that: 1) The shutdown event is set. 2) `join` is called on the hanging thread. 3) A critical error is logged after the timeout expires. 4) The process attempts to exit forcefully."
          },
          {
            "id": 5,
            "title": "Develop a Thread Monitoring and Recovery Service",
            "description": "Create a `ThreadMonitor` daemon service to track the health of critical application threads. If a monitored thread terminates unexpectedly, the monitor will log the event and publish a `THREAD_CRASHED` message to the `EventEngine`.",
            "dependencies": [
              "4.1"
            ],
            "details": "The `ThreadMonitor` will run as a `daemon=True` thread. It will expose `register(thread, name)` and `deregister(thread)` methods. In its main loop, it will periodically iterate through registered threads, check `thread.is_alive()`, and if a thread that was previously alive is now dead, it will post an event with the thread's name and ID. This allows other systems, like a connection manager, to react.",
            "status": "pending",
            "testStrategy": "Unit test the `ThreadMonitor`. Register a mock thread, then simulate its death (e.g., have the thread's run method exit immediately). Assert that the monitor detects the termination and correctly posts a `THREAD_CRASHED` event to a mock `EventEngine` with the correct payload."
          },
          {
            "id": 6,
            "title": "Refactor Connection Handling to Use a Centralized Thread Pool",
            "description": "Replace the current model of creating one dedicated thread per `StreamingBaseAdapter` with a shared, bounded `concurrent.futures.ThreadPoolExecutor`. This will improve resource management, limit system load, and centralize thread lifecycle control.",
            "dependencies": [
              "4.1"
            ],
            "details": "Instantiate a single `ThreadPoolExecutor` in a central service or the `MainEngine`. Modify `StreamingBaseAdapter`'s `connect` method to submit its long-running data processing loop to this shared pool, rather than creating its own `threading.Thread`. The `disconnect` method will need to be updated to correctly cancel the corresponding `Future` and ensure cleanup.",
            "status": "pending",
            "testStrategy": "Refactor existing adapter tests to work with the new thread pool architecture. Create a stress test that rapidly connects and disconnects many adapters, asserting that the number of active threads never exceeds the pool's configured maximum size. Verify that resources are released correctly on disconnect."
          },
          {
            "id": 7,
            "title": "Create a Comprehensive Threading and Shutdown Test Suite",
            "description": "Develop a new integration test suite focused on validating the robustness of the entire threading and shutdown system. The suite must test for race conditions, shutdown reliability, and memory leak regressions under load.",
            "dependencies": [
              "4.2",
              "4.4",
              "4.5",
              "4.6"
            ],
            "details": "This test suite (`tests/integration/test_threading.py`) will include: 1) A 'chaos' test that rapidly starts and stops adapters to look for race conditions. 2) A shutdown-under-load test that initiates a graceful shutdown while many adapters are active. 3) A validation test for the `ThreadMonitor` that kills a worker thread and confirms the recovery event is fired. 4) A long-running memory test that combines all features to ensure no new leaks have been introduced.",
            "status": "pending",
            "testStrategy": "This task is the test strategy itself. Success is defined by the creation of the test suite and all tests passing reliably in the CI/CD pipeline. The tests must be able to detect regressions in thread safety, shutdown logic, and memory management."
          }
        ]
      },
      {
        "id": 5,
        "title": "Complete TUI Implementation and Integration",
        "description": "Finalize the Textual User Interface (TUI) by resolving async integration issues, implementing robust state management and error handling, and adding comprehensive integration tests to ensure seamless interaction with the backend.",
        "details": "This task involves a full overhaul of the TUI to ensure stability, reliability, and a seamless user experience. It addresses core architectural issues from async integration to state management.\n\n1. **Async/Await Integration:**\n   - Refactor all TUI interactions with the backend `EventEngine` to be fully asynchronous. Utilize `textual`'s `run_async` method to spawn background tasks for fetching data or dispatching actions without blocking the UI thread.\n   - Ensure the application's main `asyncio` event loop and the `textual` event loop are properly integrated to prevent conflicts and deadlocks.\n\n2. **Centralized State Management:**\n   - Implement a dedicated state management system (e.g., a singleton 'Store' class using an observable pattern) to act as the single source of truth for all UI components.\n   - Widgets will subscribe to state changes rather than holding their own state. This decouples UI components from business logic and simplifies data flow (e.g., `Store.subscribe('market_data', self.on_market_data_update)`).\n\n3. **Input Validation Framework:**\n   - Integrate `Pydantic` models for all user-configurable parameters (e.g., `TradeOrderModel`).\n   - Use `textual`'s built-in `Validator` objects on input fields for real-time client-side validation (e.g., checking for numeric input, valid symbol format).\n   - On submission, validate the input data against the Pydantic model and display clear, user-friendly error messages in a dedicated status area.\n\n4. **Race Condition Mitigation & Initialization:**\n   - Modify UI panels to initially render in a 'loading' state.\n   - Panels must subscribe to backend status events (e.g., `AdapterConnectedEvent`, `InitialStateLoadedEvent`) from the `EventEngine`.\n   - Only after receiving the appropriate 'ready' event should a panel request and render its data, preventing crashes due to uninitialized backend components.\n\n5. **Error Boundaries and Graceful Degradation:**\n   - Wrap widget update logic and event handlers in `try...except` blocks to catch unexpected errors and prevent a single widget failure from crashing the entire application. Log errors to a dedicated TUI log panel.\n   - Implement handlers for backend error/disconnection events. When a connection is lost, UI elements dependent on it should enter a 'disconnected' or 'stale data' state (e.g., grayed out, showing a warning icon) instead of failing.",
        "testStrategy": "Testing will focus on the interaction between the TUI and the backend systems, ensuring both functionality and stability under various conditions.\n\n1. **Component-Level Testing (Headless):**\n   - Use `textual.pilot` to test individual widgets and screens in isolation.\n   - For each widget, simulate user input (e.g., `pilot.press()`, `pilot.click()`) and assert the resulting state changes and visual output (via screen snapshots).\n   - Mock the state store to provide data and verify that the widget renders correctly for different states (loading, data-filled, error).\n\n2. **Integration Testing (TUI + Mocked Backend):**\n   - Create a test suite that runs the full TUI application in headless mode against a mocked `EventEngine`.\n   - **Backend-to-Frontend:** Simulate the `EventEngine` firing various events (`TickEvent`, `OrderUpdateEvent`, `AdapterErrorEvent`) and assert that the corresponding TUI widgets update their content and appearance correctly.\n   - **Frontend-to-Backend:** Use `pilot` to simulate user actions like placing an order. Verify that the correct action/event is dispatched to the mocked `EventEngine` with the validated parameters.\n\n3. **Race Condition and Stress Testing:**\n   - Develop a test that rapidly fires a sequence of connection, disconnection, and data events from the mocked `EventEngine` immediately upon TUI startup. Assert that the application remains stable and does not raise any unhandled exceptions.\n\n4. **Manual E2E Verification:**\n   - Create a testing checklist for manual verification against a live (or staging) backend.\n   - The checklist must include: verifying real-time data updates, successful order submission, correct display of error messages for invalid inputs, and graceful handling of a manual backend service restart.",
        "status": "pending",
        "dependencies": [
          3,
          4
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor TUI for Full Asynchronous Operation",
            "description": "Overhaul all TUI-to-backend interactions to be fully asynchronous using textual's async capabilities, preventing UI blocking and resolving event loop conflicts.",
            "dependencies": [],
            "details": "Refactor all calls to the backend `EventEngine` to use `textual`'s `run_async` method. This ensures that long-running operations like data fetching or action dispatching occur in background tasks, keeping the UI responsive. Critically, ensure the application's main `asyncio` event loop and the `textual` event loop are correctly integrated to prevent deadlocks or race conditions.",
            "status": "pending",
            "testStrategy": "Manually verify UI responsiveness during simulated long-running backend operations. Check logs for any `asyncio` related warnings or errors. Use `textual.pilot` to trigger async actions and assert the UI does not freeze."
          },
          {
            "id": 2,
            "title": "Implement Centralized TUI State Management",
            "description": "Create a centralized 'Store' to act as the single source of truth for all UI components, simplifying data flow and decoupling UI from business logic.",
            "dependencies": [
              "5.1"
            ],
            "details": "Implement a singleton 'Store' class that manages the application's UI state. Widgets will no longer maintain their own state but will instead subscribe to relevant state changes in the Store using an observable pattern (e.g., `Store.subscribe('market_data', self.on_market_data_update)`). This change centralizes state logic and makes UI updates predictable and easier to debug.",
            "status": "pending",
            "testStrategy": "Unit test the Store class to verify that subscriptions, notifications, and state updates work correctly. Use `textual.pilot` to verify that a widget correctly updates its view when the corresponding state in the Store is changed externally."
          },
          {
            "id": 3,
            "title": "Integrate Pydantic-Based Input Validation",
            "description": "Implement a robust, two-tiered input validation system using `textual`'s real-time validators and `Pydantic` models for submission-time validation.",
            "dependencies": [
              "5.2"
            ],
            "details": "For all user inputs (e.g., trade orders, configuration settings), apply `textual.Validator` objects directly to input fields for immediate feedback (e.g., numeric-only, regex patterns). On form submission, validate the collected data against a corresponding `Pydantic` model. If validation fails, display clear, user-friendly error messages in a dedicated status widget, which reads its content from the central state.",
            "status": "pending",
            "testStrategy": "Use `textual.pilot` to enter both valid and invalid data into input fields. Assert that client-side validators prevent invalid characters and that Pydantic validation errors are correctly displayed in the status area upon submission attempts."
          },
          {
            "id": 4,
            "title": "Mitigate Initialization Race Conditions with Loading States",
            "description": "Prevent UI crashes on startup by ensuring widgets render in a 'loading' state and only request data after the backend confirms it is ready.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Modify all data-dependent widgets to initially display a 'loading' or placeholder state. Each widget must subscribe to backend status events (e.g., `AdapterConnectedEvent`, `InitialStateLoadedEvent`) via the `EventEngine` and state store. Only after receiving the necessary 'ready' event will the widget trigger an async task to fetch and render its initial data, eliminating race conditions where the UI requests data from an uninitialized backend.",
            "status": "pending",
            "testStrategy": "Use `textual.pilot` to launch the application with a simulated delay in backend initialization. Verify that all relevant panels correctly display their 'loading' state and transition to a 'data-loaded' state only after a mock `InitialStateLoadedEvent` is processed."
          },
          {
            "id": 5,
            "title": "Implement Widget-Level Error Boundaries",
            "description": "Wrap widget update logic in `try...except` blocks to isolate failures, preventing a single widget error from crashing the entire TUI.",
            "dependencies": [
              "5.1"
            ],
            "details": "Encapsulate the core logic within event handlers and data update methods of each major widget (e.g., Order Book, Charts, Positions Panel) inside a `try...except` block. Any caught exceptions should be logged to a dedicated TUI log panel for debugging and prevent the exception from propagating and crashing the application. The widget should ideally display a localized error state.",
            "status": "pending",
            "testStrategy": "Inject faulty data or raise exceptions deliberately within a widget's update method during a test. Use `textual.pilot` to verify that the specific widget shows an error state but the rest of the application remains responsive and functional."
          },
          {
            "id": 6,
            "title": "Implement Graceful Degradation on Backend Disconnection",
            "description": "Ensure the UI remains stable and informative when the backend connection is lost by transitioning data-dependent widgets to a 'disconnected' state.",
            "dependencies": [
              "5.1",
              "5.2"
            ],
            "details": "Create handlers for backend disconnection and error events. When such an event is received, update the central state to reflect the disconnected status. Widgets subscribed to this state should automatically re-render into a 'disconnected' or 'stale data' mode (e.g., grayed out, displaying a warning icon, showing last known values). This provides clear feedback to the user and prevents errors from attempting to interact with a disconnected backend.",
            "status": "pending",
            "testStrategy": "Simulate a backend disconnection event. Use `textual.pilot` to assert that all relevant UI components change their appearance to a 'disconnected' state and that interactive elements that require a connection (e.g., 'Place Order' button) become disabled."
          },
          {
            "id": 7,
            "title": "Develop Comprehensive TUI Integration Test Suite",
            "description": "Create a suite of headless integration tests using `textual.pilot` to validate the end-to-end functionality, stability, and responsiveness of the TUI.",
            "dependencies": [
              "5.1",
              "5.2",
              "5.3",
              "5.4",
              "5.5",
              "5.6"
            ],
            "details": "Using the `textual.pilot` testing framework, create a test suite that simulates user interactions and verifies the TUI's response. Tests should cover key user workflows: entering and submitting orders, navigating between screens, and verifying data updates from mock backend events. The suite will run headlessly in CI/CD to catch regressions.",
            "status": "pending",
            "testStrategy": "The implementation of this task *is* the test strategy for the parent task. The suite will cover component-level tests (widget isolation) and screen-level tests (workflow simulation) to ensure the entire TUI is stable and interacts correctly with a mocked backend."
          }
        ]
      },
      {
        "id": 6,
        "title": "Fix and Enhance Test Infrastructure",
        "description": "Overhaul the project's testing infrastructure by resolving dependency issues, creating a stable test environment, fixing broken tests, and implementing a CI pipeline, performance benchmarking, and WebSocket mocking.",
        "details": "1. **Dependency Management Consolidation:**\n   - Identify and add the missing `packaging` module to the project's core dependencies.\n   - Audit all existing code (including from Tasks 1 & 3) to identify all required libraries (e.g., `ccxt`, `ccxt.pro`, `textual`, `pytest`, `pytest-benchmark`, `pytest-asyncio`).\n   - Consolidate all project and development dependencies into `pyproject.toml` under `[project.dependencies]` and `[project.optional-dependencies]`, deprecating any `requirements.txt` files.\n\n2. **Test Environment Setup:**\n   - Create a `Makefile` or a shell script (`scripts/setup-dev.sh`) that automates the creation of a virtual environment and installation of all project and test dependencies using `pip install -e .[test]`.\n   - Ensure the script is executable and documented in the project's `README.md`.\n\n3. **Test Codebase Refactoring:**\n   - Systematically review all files under the `tests/` directory.\n   - Correct all broken `import` statements and file paths that resulted from recent refactoring. Ensure all tests can be discovered and run by `pytest` from the project root.\n\n4. **WebSocket Mocking Framework:**\n   - Create a new mock server/client infrastructure in `tests/mocks/websocket.py`.\n   - The mock must be able to simulate the lifecycle of a WebSocket connection as defined in Task 3: successful connection, authentication, subscription, data message pushes (e.g., mock trades, order book updates), heartbeats, and graceful/abrupt disconnections.\n   - It should be easily configurable within `pytest` fixtures to simulate various scenarios, including high-volume data and error conditions.\n\n5. **Performance Benchmarking Suite:**\n   - Integrate the `pytest-benchmark` library.\n   - Create a new test suite `tests/performance/` for benchmarking critical code paths.\n   - Initial benchmarks should target data transformation logic in adapters and event processing throughput in the `EventEngine`.\n\n6. **Continuous Integration (CI) Pipeline:**\n   - Set up a CI workflow using GitHub Actions (in `.github/workflows/ci.yml`).\n   - The pipeline should trigger on every push and pull request to the `main` branch.\n   - Workflow steps must include:\n     - Checking out the code.\n     - Setting up a specific Python version.\n     - Installing dependencies using the new setup script.\n     - Running static analysis/linting tools (e.g., `flake8`, `black`).\n     - Executing the full `pytest` suite.",
        "testStrategy": "1. **Environment Script Verification:**\n   - In a clean, containerized environment (e.g., Docker), execute the new setup script. Verify that the virtual environment is created and all dependencies from `pyproject.toml` are installed correctly.\n   - Confirm that `pytest` can be run successfully from the command line after setup.\n\n2. **CI Pipeline Validation:**\n   - Create a test branch and a pull request.\n   - Confirm that the CI pipeline triggers automatically.\n   - Intentionally introduce a failing test and a linting error to ensure the respective CI steps fail as expected.\n   - Fix the errors and confirm the pipeline passes successfully.\n\n3. **Mock Infrastructure Test:**\n   - Write a new unit test for a component that will use the WebSocket streaming (e.g., a test for the `StreamingBaseAdapter`).\n   - Use the new WebSocket mock fixture to simulate a data stream and assert that the component processes the mock data correctly. This validates the usability of the mock framework.\n\n4. **Benchmark Execution:**\n   - Run the performance test suite locally using `pytest --benchmark-only`.\n   - Verify that benchmark results are generated and saved. Review the initial report to establish a performance baseline.\n\n5. **Full Test Suite Execution:**\n   - Run the entire test suite (`pytest`) from the project root. Assert that all tests pass, confirming that broken imports and paths have been resolved.",
        "status": "pending",
        "dependencies": [
          1,
          3
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Consolidate Project Dependencies into pyproject.toml",
            "description": "Audit the entire codebase to identify all production and development dependencies, and consolidate them into a single `pyproject.toml` file, deprecating any existing `requirements.txt` files.",
            "dependencies": [],
            "details": "Identify all required libraries, including `packaging`, `ccxt`, `ccxt.pro`, `textual`, `pytest`, `pytest-benchmark`, and `pytest-asyncio`. Add production libraries to `[project.dependencies]` and development/testing libraries to `[project.optional-dependencies.test]`.",
            "status": "pending",
            "testStrategy": "Manually inspect the `pyproject.toml` file for correctness. The ultimate test will be the successful execution of the setup script in the next subtask."
          },
          {
            "id": 2,
            "title": "Create Automated Development Environment Setup Script",
            "description": "Develop a script to automate the creation of a virtual environment and the installation of all project and test dependencies from the `pyproject.toml` file.",
            "dependencies": [
              "6.1"
            ],
            "details": "Create a `Makefile` or a shell script (e.g., `scripts/setup-dev.sh`) that automates the setup process. The script should execute `pip install -e .[test]`. Ensure the script is executable and document its usage in the `README.md`.",
            "status": "pending",
            "testStrategy": "Execute the script in a clean, containerized environment (e.g., Docker) to verify it creates a virtual environment and installs all dependencies correctly. Confirm `pytest` can be invoked."
          },
          {
            "id": 3,
            "title": "Refactor and Fix Broken Test Suite Imports",
            "description": "Systematically review and repair the existing test suite under the `tests/` directory by fixing all broken import statements and incorrect file paths resulting from recent code refactoring.",
            "dependencies": [
              "6.2"
            ],
            "details": "Go through each file in the `tests/` directory and correct all `import` statements. The goal is to make the entire test suite discoverable and runnable by `pytest` from the project root without any import-related errors.",
            "status": "pending",
            "testStrategy": "Run `pytest` from the project root. Success is defined as `pytest` discovering and running all existing tests without raising any `ModuleNotFoundError` or `ImportError` exceptions."
          },
          {
            "id": 4,
            "title": "Implement WebSocket Mocking Framework",
            "description": "Create a configurable and reusable WebSocket mocking framework to simulate real-time data streams for testing exchange adapters.",
            "dependencies": [
              "6.3"
            ],
            "details": "Develop a mock server/client in `tests/mocks/websocket.py`. It must simulate the full WebSocket lifecycle: connection, authentication, subscription, data messages, heartbeats, and disconnections. It should be integrated with `pytest` fixtures for easy configuration in tests.",
            "status": "pending",
            "testStrategy": "Write new unit tests that utilize the mock fixtures. These tests should assert that the application logic correctly handles various simulated WebSocket events, including successful data reception and error conditions."
          },
          {
            "id": 5,
            "title": "Establish Performance Benchmarking Suite",
            "description": "Integrate the `pytest-benchmark` library and create an initial suite of performance tests for critical application components.",
            "dependencies": [
              "6.3"
            ],
            "details": "Add and configure `pytest-benchmark`. Create a new test suite in `tests/performance/`. Implement initial benchmarks targeting data transformation logic within adapters and the event processing throughput of the `EventEngine`.",
            "status": "pending",
            "testStrategy": "Run `pytest --benchmark-only` to ensure the new performance tests execute and generate reports. Analyze the initial results to establish a performance baseline."
          },
          {
            "id": 6,
            "title": "Set Up CI Workflow with Static Analysis",
            "description": "Create a foundational Continuous Integration (CI) pipeline using GitHub Actions that automatically performs linting and static code analysis.",
            "dependencies": [
              "6.2"
            ],
            "details": "Create a `.github/workflows/ci.yml` file. The workflow must trigger on pushes and pull requests to `main`. It should include steps to check out code, set up Python, install dependencies via the setup script, and run static analysis tools like `flake8` and `black --check`.",
            "status": "pending",
            "testStrategy": "Create a pull request with intentional linting errors to verify that the CI pipeline correctly identifies the issues and fails. Subsequently, fix the errors and confirm the pipeline passes."
          },
          {
            "id": 7,
            "title": "Integrate Full Test Suite into CI Pipeline",
            "description": "Enhance the CI pipeline to execute the complete test suite, including all unit, integration, and performance tests, to validate code changes.",
            "dependencies": [
              "6.3",
              "6.4",
              "6.5",
              "6.6"
            ],
            "details": "Add a new step to the `ci.yml` workflow that executes the full `pytest` suite. This step should run after the static analysis step has passed. The CI run's success or failure must depend on the test results.",
            "status": "pending",
            "testStrategy": "Create a pull request with a deliberately failing test to ensure the CI pipeline fails at the testing step. After fixing the test, confirm that the entire CI pipeline completes successfully."
          }
        ]
      },
      {
        "id": 7,
        "title": "Complete Logging Migration",
        "description": "Overhaul the application's logging system by migrating all print statements to loguru, implementing structured JSON logging, optimizing performance in hot-paths, and adding robust configuration, rotation, and metrics collection.",
        "details": "This task involves a complete refactoring of the application's logging infrastructure to establish a modern, performant, and maintainable system.\n\n1. **Audit and Migrate to Loguru:**\n   - Perform a codebase-wide search for all instances of `print()`.\n   - Replace each `print()` statement with an appropriate `loguru` logger call (e.g., `logger.debug()`, `logger.info()`, `logger.warning()`, `logger.error()`).\n   - Differentiate between temporary debug prints, which should become `logger.debug()`, and essential operational messages, which should be `logger.info()` or higher.\n\n2. **Implement Structured Logging:**\n   - Configure `loguru` to serialize all log records to JSON format for file-based sinks. The console sink can remain human-readable for development.\n   - The standard JSON log entry must include: `timestamp`, `level`, `message`, `name`, `function`, and `line`.\n   - Utilize `logger.bind()` to add structured context to logs where appropriate (e.g., `logger.bind(exchange='binance', symbol='BTC/USDT').info('Order book updated')`).\n\n3. **Hot-Path Performance Optimization:**\n   - Identify performance-critical code paths, specifically within the WebSocket message handling loops (from Task 3) and the core `EventEngine`.\n   - Configure `loguru` sinks with `enqueue=True` to make logging calls in these hot-paths non-blocking, preventing I/O from impacting application latency.\n   - The default production log level should be set to `INFO` to avoid the performance cost of processing `DEBUG` level messages.\n\n4. **Centralized Configuration System:**\n   - Create a `logging.yaml` or similar configuration file to manage all logging settings.\n   - The application must load this configuration on startup.\n   - The configuration file will control sinks (file, console), log levels per module, format (JSON vs. plain text), rotation, and retention policies.\n\n5. **Log Rotation and Archival:**\n   - Configure file sinks to use built-in `loguru` rotation based on size (e.g., `rotation='100 MB'`) and time (e.g., `rotation='00:00'`).\n   - Implement a retention policy to automatically clean up old log files (e.g., `retention='14 days'`).\n   - Enable compression for rotated log files to save disk space (e.g., `compression='zip'`).\n\n6. **Performance Metrics Collection:**\n   - Establish a dedicated logger for performance metrics.\n   - This logger will write to a separate `metrics.log` file in a machine-parseable format (e.g., key-value or JSON).\n   - Instrument key functions to log execution time, e.g., `logger_metrics.info(f'event_processing_time={{duration}}ms')`.",
        "testStrategy": "1. **Static Code Analysis:**\n   - Run a script (`grep -r 'print(' ./src`) to verify that no `print()` statements remain in the main application source code. Exceptions for specific tools or scripts must be justified.\n\n2. **Structured Log Validation:**\n   - In unit tests, redirect log output to an in-memory stream (e.g., `io.StringIO`).\n   - Generate a log message with bound context using `logger.bind()`.\n   - Parse the resulting JSON from the stream and assert that all required fields (`timestamp`, `level`, `message`) and the custom context fields are present and correctly formatted.\n\n3. **Configuration Testing:**\n   - Write unit tests that load different logging configuration files.\n   - Assert that the logger's level and sink configurations change as expected based on the loaded file.\n   - Test edge cases like malformed configuration files, ensuring the application handles them gracefully.\n\n4. **Rotation and Retention Simulation:**\n   - Write an integration test that generates enough log data to trigger a size-based rotation. Verify that a new log file is created and the old one is archived/compressed.\n   - Use a library like `freezegun` to manipulate the system clock and test time-based rotation (e.g., daily) and retention (e.g., deleting files older than 7 days).\n\n5. **Performance Benchmarking:**\n   - Using the test infrastructure from Task 6, create benchmarks for a hot-path function (e.g., a WebSocket message handler).\n   - Run the benchmark with logging disabled, with synchronous logging, and with asynchronous (`enqueue=True`) logging.\n   - Assert that the performance degradation from asynchronous logging is minimal and within an acceptable threshold compared to synchronous logging.",
        "status": "pending",
        "dependencies": [
          3,
          4,
          6
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "Audit and Replace `print()` with Basic Loguru Calls",
            "description": "Perform a comprehensive codebase audit to find all instances of `print()` and replace them with the appropriate `loguru` equivalent. This initial pass will establish a baseline for the new logging system.",
            "dependencies": [],
            "details": "Use a global search tool (e.g., `grep`, IDE search) to locate all `print()` statements. Replace them with `logger.debug()` for temporary or verbose development messages, and `logger.info()`, `logger.warning()`, or `logger.error()` for significant operational events. A single, globally configured logger is sufficient for this stage.",
            "status": "pending",
            "testStrategy": "Run a static code analysis script (e.g., `grep -r 'print(' ./src`) to confirm that no `print()` statements remain in the main application source code. Manually review a sample of the replacements to ensure correct log levels were chosen."
          },
          {
            "id": 2,
            "title": "Implement Centralized YAML-based Logging Configuration",
            "description": "Create a `logging.yaml` file and a corresponding loader module. The application must parse this file on startup to dynamically configure all aspects of the logging system, decoupling configuration from the code.",
            "dependencies": [],
            "details": "The configuration file should define sections for sinks, log levels (global and per-module), and formats. The loader module will be responsible for reading the YAML, removing `loguru`'s default handler, and adding new handlers as specified in the configuration.",
            "status": "pending",
            "testStrategy": "Write unit tests for the configuration loader. Verify that it correctly parses a sample YAML file and that the `loguru` logger object is configured with the expected handlers and levels."
          },
          {
            "id": 3,
            "title": "Configure Structured JSON and Human-Readable Console Sinks",
            "description": "Using the new configuration system, implement two primary logging sinks: a human-readable, colorized sink for console output during development, and a structured JSON sink for file output.",
            "dependencies": [
              "7.2"
            ],
            "details": "In `logging.yaml`, define a console sink with standard formatting and a file sink with `serialize=True`. The JSON output must include standard fields like `timestamp`, `level`, `message`, `name`, `function`, and `line` to facilitate automated parsing and analysis.",
            "status": "pending",
            "testStrategy": "In a test environment, capture log output. Verify the console output is human-readable. Read the generated log file and use a JSON parser to validate that each line is a well-formed JSON object matching the required schema."
          },
          {
            "id": 4,
            "title": "Implement Log Rotation, Retention, and Compression",
            "description": "Enhance the file-based JSON sink to include robust, production-ready features for log file management, including automatic rotation, retention, and compression.",
            "dependencies": [
              "7.3"
            ],
            "details": "Extend the file sink configuration in `logging.yaml` to include parameters for `rotation` (e.g., '100 MB' or '00:00'), `retention` (e.g., '14 days'), and `compression` (e.g., 'zip'). `loguru` will handle the lifecycle of these files automatically.",
            "status": "pending",
            "testStrategy": "Create a test script that generates a large volume of logs to trigger the size-based rotation. Manually inspect the log directory to confirm that files are rotated, compressed into zip archives, and that old files are purged according to the retention policy."
          },
          {
            "id": 5,
            "title": "Optimize Logging Performance in Hot-Paths",
            "description": "Identify performance-critical code paths, specifically the WebSocket message handling loops and the core EventEngine, and configure their logging to be non-blocking to prevent I/O latency from impacting application performance.",
            "dependencies": [
              "7.3"
            ],
            "details": "In the `logging.yaml` configuration, set `enqueue=True` for the file sink. This offloads the I/O operations to a separate process. Additionally, set the default production log level to `INFO` to avoid the performance cost of serializing and processing `DEBUG` messages.",
            "status": "pending",
            "testStrategy": "Conduct a benchmark test on a critical function (e.g., WebSocket message processor). Measure the execution latency with `enqueue=False` and `enqueue=True` to verify that non-blocking logging significantly reduces I/O-related delays."
          },
          {
            "id": 6,
            "title": "Enrich Logs with Structured Context using `logger.bind()`",
            "description": "Refactor key application modules to add dynamic, structured context to log records. This will make logs more searchable and useful for debugging without cluttering the log message itself.",
            "dependencies": [
              "7.1",
              "7.3"
            ],
            "details": "In areas handling specific contexts, such as an exchange adapter or order manager, use `logger.bind(exchange='binance', symbol='BTC/USDT')` to create context-specific loggers. This bound data will automatically be included as key-value pairs in the JSON log output.",
            "status": "pending",
            "testStrategy": "In unit tests for modules like exchange adapters, trigger a log-producing event. Capture the JSON log output and assert that the record contains the extra context fields (e.g., 'extra.exchange': 'binance') that were added via `bind()`."
          },
          {
            "id": 7,
            "title": "Implement Dedicated Performance Metrics Logging",
            "description": "Establish a separate logger and file sink (`metrics.log`) specifically for collecting performance metrics in a machine-parseable format, distinct from the main application event logs.",
            "dependencies": [
              "7.2"
            ],
            "details": "Add a new sink to `logging.yaml` for `metrics.log`, configured to use JSON serialization. Create a dedicated logger instance (e.g., `metrics_logger`). Instrument key functions to log metrics like execution time or queue size, e.g., `metrics_logger.info('event_processing', duration_ms=55)`.",
            "status": "pending",
            "testStrategy": "Write a unit test that executes an instrumented function. Verify that a new line is written to `metrics.log` and that it is a valid JSON object containing the expected metric name and value (e.g., `{'message': 'event_processing', 'extra': {'duration_ms': 55}}`)."
          }
        ]
      },
      {
        "id": 8,
        "title": "Implement Native WebSocket Streaming for Futu Adapter",
        "description": "Create a bespoke WebSocket streaming implementation for the Futu adapter using its native futu-api SDK. This involves building connection management, data parsing, and event transformation from scratch to handle Futu's unique API architecture and data formats.",
        "details": "This task requires a high-effort, native implementation as it cannot use the unified CCXT library. The implementation must adhere to the framework's streaming architecture.\n\n1. **Dependency Integration:**\n   - Add the `futu-api` library to the project's dependencies in `pyproject.toml`.\n\n2. **Adapter Implementation (`FutuAdapter`):**\n   - Create a new `FutuAdapter` class that inherits from the `StreamingBaseAdapter` defined in Task #3.\n   - Implement the required `connect()`, `disconnect()`, `subscribe()`, and `unsubscribe()` methods.\n\n3. **Connection and Authentication:**\n   - The `connect()` method must handle the connection to the FutuOpenD client, including configuration for host, port, and the trading password required to unlock the API.\n   - Implement robust logic for handling connection state, including automatic reconnection attempts with exponential backoff upon disconnection.\n\n4. **Subscription Management:**\n   - The `subscribe()` method must map the framework's standardized symbol format to Futu's specific instrument codes and data types (e.g., `SubType.QUOTE`, `SubType.ORDER_BOOK`).\n   - Maintain an internal state of active subscriptions to prevent duplicates and manage unsubscriptions correctly.\n\n5. **Data Parsing and Transformation:**\n   - Register callback handlers with the `futu-api` client (e.g., using `set_handler`).\n   - Implement parsers within these handlers to process the native Futu data formats (often pandas DataFrames) for quotes, order books, and trades.\n   - Transform the parsed data into the framework's standardized event objects (`TickEvent`, `OrderBookEvent`, etc.) and push them to the `EventEngine` for system-wide consumption.\n\n6. **Error Handling:**\n   - Implement comprehensive error handling for API-specific issues, such as authentication failure, invalid subscription requests, rate limits, and connection errors. Log all errors using the structured logging system.",
        "testStrategy": "1. **Unit Testing (Mocked SDK):**\n   - In `tests/unit/adapter/futu/`, create a comprehensive test suite that uses a mock of the `futu-api`'s `OpenQuoteContext`.\n   - **Connection Lifecycle:** Simulate connection success, authentication failure, and disconnection events. Assert that the adapter's internal state changes correctly.\n   - **Data Transformation:** Create mock Futu data payloads (for quotes, order books) and pass them to the adapter's callback handlers. Assert that the correct, fully-populated `foxtrot` event objects are generated and passed to the mocked `EventEngine`.\n   - **Subscription Logic:** Verify that calls to the adapter's `subscribe()` and `unsubscribe()` methods result in the correct underlying `futu-api` functions being called with the correct parameters.\n\n2. **Integration Testing (Live Client):**\n   - In `tests/integration/adapter/futu/`, create tests that connect to a live (or paper trading) instance of the FutuOpenD client. These tests should be marked to be skipped in CI environments where the client is unavailable.\n   - The test should perform a full lifecycle: connect, authenticate, subscribe to a real-time instrument (e.g., `HK.00700`), receive at least one `TickEvent`, and then gracefully disconnect.\n\n3. **Longevity and Stability Testing:**\n   - Develop a long-running test that leaves the adapter connected and subscribed for an extended period (e.g., 30+ minutes) to check for memory leaks or connection stability issues, leveraging the profiling and monitoring tools from Task #4.",
        "status": "pending",
        "dependencies": [
          3,
          4,
          6
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement Native WebSocket Streaming for Interactive Brokers Adapter",
        "description": "Create a dedicated task for implementing WebSocket streaming for the Interactive Brokers adapter using its native ibapi SDK, handling its complex event-driven architecture, TWS/Gateway integration, and unique callback system.",
        "details": "This task requires a high-effort, bespoke implementation due to the unique architecture of the Interactive Brokers API. Unlike unified libraries, this involves direct integration with the `ibapi` Python SDK, managing a persistent connection to the Trader Workstation (TWS) or IB Gateway, and handling its asynchronous, callback-driven nature.\n\n1. **Dependency Integration:**\n   - Add the official `ibapi` library to the project's dependencies in `pyproject.toml`.\n\n2. **Adapter Implementation (`InteractiveBrokersAdapter`):\n   - Create a new `InteractiveBrokersAdapter` class that inherits from the `StreamingBaseAdapter` defined in Task #3.\n   - The adapter will implement a wrapper around the `ibapi.EClient` and `ibapi.EWrapper` classes.\n\n3. **Connection and Thread Management:**\n   - The `connect()` method will instantiate the `EClient` and a custom `EWrapper` subclass. It will then call `client.connect(host, port, clientId)` and start the client's event processing loop (`client.run()`) in a dedicated background thread, leveraging the robust threading model from Task #4.\n   - The `disconnect()` method must gracefully call `client.disconnect()` and ensure the background thread is properly joined.\n\n4. **Callback-Driven Event Handling:**\n   - The custom `EWrapper` subclass will override methods like `tickPrice()`, `tickSize()`, `orderStatus()`, `openOrder()`, and `error()`.\n   - Inside these callback methods, transform the raw IB data into the framework's standardized event objects (e.g., `TickEvent`, `OrderEvent`).\n   - Push the transformed events onto the central `EventEngine` for consumption by other parts of the system.\n\n5. **Subscription Management:**\n   - The `subscribe(symbol)` method will generate a unique request ID (`tickerId`) and call the appropriate client method, such as `client.reqMktData(tickerId, contract, ...)`. The adapter must maintain a mapping between `tickerId` and the symbol.\n   - The `unsubscribe(symbol)` method will use the stored `tickerId` to call `client.cancelMktData(tickerId)`.",
        "testStrategy": "Testing must focus on mocking the complex, stateful, and callback-based nature of the `ibapi` SDK.\n\n1. **Unit Testing (Mocked SDK):**\n   - In `tests/unit/adapter/ib/`, create a comprehensive test suite that mocks the `ibapi.EClient` and the custom `EWrapper`.\n   - **Connection Lifecycle:** Simulate connection success by triggering the `connectAck` callback. Simulate failures by triggering the `error` callback with connection-related error codes. Assert that the adapter's internal state (`is_connected`) updates correctly.\n   - **Subscription and Data Flow:**\n     - Test that calling `adapter.subscribe(symbol)` results in a call to the mocked `EClient.reqMktData` with the correct `tickerId` and a properly formed `Contract` object.\n     - Manually invoke callback methods on the adapter's `EWrapper` instance (e.g., `wrapper.tickPrice(tickerId, tickType, price, ...)`). Assert that the adapter correctly identifies the symbol from the `tickerId`, transforms the data into a standard `TickEvent`, and puts it on the mocked `EventEngine`.\n   - **Error Handling:** Simulate API errors by invoking the `error(reqId, errorCode, errorString)` callback. Verify that the error is logged correctly using the logging system from Task #7 and that the system remains stable.\n   - **Unsubscription:** Test that `adapter.unsubscribe(symbol)` correctly calls `EClient.cancelMktData` with the corresponding `tickerId`.\n\n2. **Integration Testing (Manual):**\n   - As a final verification step, manually run the adapter against a paper-trading account via TWS or IB Gateway. Subscribe to a few instruments and monitor the logs to ensure a stable stream of correctly formatted data is received.",
        "status": "pending",
        "dependencies": [
          3,
          4,
          6,
          7
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-27T17:18:34.572Z",
      "updated": "2025-08-03T15:01:29.478Z",
      "description": "Tasks for master context"
    }
  }
}